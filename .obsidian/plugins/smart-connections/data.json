{
  "new_user": false,
  "legacy_transformers": false,
  "enable_mobile": true,
  "actions": {
    "lookup": true
  },
  "system_prompts_folder": "smart prompts",
  "smart_chat_folder": "smart-chats",
  "smart_chat_folder_last": "smart-chats",
  "chat_model_platform_key": "open_router",
  "open_router": {
    "api_key": "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",
    "model_name": "meta-llama/llama-3.2-3b-instruct:free",
    "description": "Meta: Llama 3.2 3B Instruct (free)",
    "type": "API",
    "endpoint": "https://openrouter.ai/api/v1/chat/completions",
    "streaming": true,
    "adapter": "OpenRouter",
    "fetch_models": true,
    "default_model": "meta-llama/llama-3.1-8b-instruct:free",
    "signup_url": "https://accounts.openrouter.ai/sign-up?redirect_url=https%3A%2F%2Fopenrouter.ai%2Fkeys",
    "key": "meta-llama/llama-3.2-3b-instruct:free",
    "max_input_tokens": 131072,
    "actions": true,
    "multimodal": false,
    "raw": {
      "id": "meta-llama/llama-3.2-3b-instruct:free",
      "name": "Meta: Llama 3.2 3B Instruct (free)",
      "created": 1727222400,
      "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).\n\n_These are free, rate-limited endpoints for [Llama 3.2 3B Instruct](/models/meta-llama/llama-3.2-3b-instruct). Outputs may be cached. Read about rate limits [here](/docs/limits)._",
      "context_length": 131072,
      "architecture": {
        "modality": "text->text",
        "tokenizer": "Llama3",
        "instruct_type": "llama3"
      },
      "pricing": {
        "prompt": "0",
        "completion": "0",
        "image": "0",
        "request": "0"
      },
      "top_provider": {
        "context_length": 8192,
        "max_completion_tokens": 4096,
        "is_moderated": false
      },
      "per_request_limits": null
    }
  },
  "api_key": "",
  "excluded_headings": "",
  "folder_exclusions": "smart-chats",
  "show_full_path": false,
  "expanded_view": true,
  "language": "en",
  "version": "2.2.79"
}